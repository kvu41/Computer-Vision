{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Res_Unet.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYso7BJ2yOBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Deep Learning Data/Skin Cancer/train.zip\"\n",
        "!unzip \"/content/drive/My Drive/Deep Learning Data/Skin Cancer/ISIC-2017_Training_Part1_GroundTruth.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03j1J6-_zEbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "#List directory\n",
        "mask_dir = \"/content/ISIC-2017_Training_Part1_GroundTruth\"\n",
        "melanoma_dir =\"/content/train/melanoma\"\n",
        "nevus_dir = \"/content/train/nevus\"\n",
        "keratosis_dir = \"/content/train/seborrheic_keratosis\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbdPlT4a037Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_ids = os.listdir(mask_dir)\n",
        "melanoma_ids = os.listdir(melanoma_dir)\n",
        "nevus_mask =  os.listdir(nevus_dir)\n",
        "keratosis_mask = os.listdir(keratosis_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmlDABH908jU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a93bb5b7-ee85-4863-eeb2-419021895372"
      },
      "source": [
        "print(f\" Total numer of masks:  {len(mask_ids)}\")\n",
        "print(f\" Total numer of melanoma :  {len(melanoma_ids)}\")\n",
        "print(f\" Total numer of nevus :  {len(nevus_mask)}\")\n",
        "print(f\" Total numer of keratosis :  {len(keratosis_mask)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Total numer of masks:  2000\n",
            " Total numer of melanoma :  374\n",
            " Total numer of nevus :  1372\n",
            " Total numer of keratosis :  254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_11BUP_09UM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential\n",
        "\n",
        "def resblock(in_put, n_in, n_out):\n",
        "    input_shape = in_put.shape[2]\n",
        "    resblock = Sequential(nn.Conv2d(in_channels = n_in, out_channels = n_out, kernel_size = 3, stride = 1, padding =1),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Conv2d(in_channels = n_out, out_channels = n_out, kernel_size = 1, stride = 1 , padding = 0),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Conv2d(in_channels = n_out, out_channels = n_out, kernel_size = 3, stride = 1, padding = 1))\n",
        "    return resblock(in_put)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVTuyx5s4oX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1093d28b-9fd2-4879-ab56-e64cb0ab25dc"
      },
      "source": [
        "### Test block input (64, 3,256,256) - > out_put (64, 64, 256, 256)\n",
        "image = torch.randint(low = 0, high = 256, size = (64, 3, 256, 256)).type(torch.float32)\n",
        "\n",
        "out_image = resblock(image, n_in = image.shape[1], n_out = 64)\n",
        "\n",
        "print(f\"Shape of the output image: {out_image.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the output image: torch.Size([64, 64, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPy3P3h57bsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential, functional as F\n",
        "class ResUnet(nn.Module):\n",
        "    def __init__(self, identity_block, image_size, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.image_size = image_size\n",
        "        self.identity = resblock\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size =2, stride = 2) ## reduce input size by half\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "        ## Image input size as tensor of shape (batch_size, no_channels, image_size, image_size)\n",
        "        x = F.relu(self.identity(image, n_in = image.shape[1], n_out = 64))\n",
        "        x = self.dropout(x)\n",
        "        x1 = F.relu(self.identity(x, n_in = 64, n_out = 64)) \n",
        "\n",
        "        ##Maxpooling to reduce size of images\n",
        "        x2 = self.maxpool(x1)## return tensor (batch_size, 64, image_size/2, image_size/2)\n",
        "        x2 = F.relu(self.identity(x2, n_in = x2.shape[1], n_out = x2.shape[1]*2))\n",
        "        x2 = self.dropout(x2)\n",
        "        x2 = F.relu(self.identity(x2, n_in =x2.shape[1], n_out = x2.shape[1]))## Return (batch_size, 128, image_size/2, image_size/2)\n",
        "\n",
        "        ### Maxpooling to reduce size of images\n",
        "        x3 = self.maxpool(x2)\n",
        "        x3 = F.relu(self.identity(x3, n_in = x3.shape[1], n_out = x3.shape[1]*2))\n",
        "        x3 = self.dropout(x3)\n",
        "        x3 = F.relu(self.identity(x3, n_in = x3.shape[1], n_out = x3.shape[1]))\n",
        "\n",
        "        ##Maxpooling to reduce size of images\n",
        "        x4= self.maxpool(x3)\n",
        "        x4 = F.relu(self.identity(x4, n_in = x4.shape[1], n_out = x4.shape[1]*2))\n",
        "        x4 = self.dropout(x4)\n",
        "        x4 = F.relu(self.identity(x4, n_in = x4.shape[1], n_out = x4.shape[1]))\n",
        "\n",
        "        ## Max pooling to reduce size of image\n",
        "        x5 = self.maxpool(x4)\n",
        "        x5 = F.relu(self.identity(x5, n_in =x5.shape[1], n_out = x5.shape[1]))\n",
        "        x5 = self.dropout(x5)\n",
        "        \n",
        "\n",
        "        ##Upsampling \n",
        "        up1 = nn.ConvTranspose2d(in_channels = x5.shape[1], out_channels = x5.shape[1],kernel_size= 2, stride = 2, padding = 0)(x5)\n",
        "        cat1 = torch.cat([x4, up1], dim =1)\n",
        "        cat1 = F.relu(nn.BatchNorm2d(num_features=cat1.shape[1])(cat1))\n",
        "        cat1 = self.dropout(cat1)  ### return images with 1024 channels\n",
        "\n",
        "        ## Reduce no_of channel by half\n",
        "        cat1 = F.relu(self.identity(cat1, n_in = cat1.shape[1], n_out = int(cat1.shape[1]/2)))# 512\n",
        "        cat1 = self.dropout(cat1)\n",
        "        cat1 = F.relu(self.identity(cat1, n_in = cat1.shape[1], n_out = int(cat1.shape[1]/2))) #256\n",
        "\n",
        "        ## Upsampling\n",
        "        up2 = nn.ConvTranspose2d(in_channels = cat1.shape[1], out_channels = cat1.shape[1],kernel_size= 2, stride = 2, padding = 0)(cat1)\n",
        "        cat2 = torch.cat([x3, up2], dim =1)# 512\n",
        "        cat2 = F.relu(nn.BatchNorm2d(num_features=cat2.shape[1])(cat2))\n",
        "        cat2 = self.dropout(cat2) # \n",
        "\n",
        "        ## Reduce no_of channel by half\n",
        "        cat2 = F.relu(self.identity(cat2, n_in = cat2.shape[1], n_out = int(cat2.shape[1]/2))) #256\n",
        "        cat2 = self.dropout(cat2)\n",
        "        cat2 = F.relu(self.identity(cat2, n_in = cat2.shape[1], n_out = int(cat2.shape[1]/2))) #128\n",
        "\n",
        "        ## Upsampling\n",
        "        up3 = nn.ConvTranspose2d(in_channels = cat2.shape[1], out_channels = cat2.shape[1],kernel_size= 2, stride = 2, padding = 0)(cat2)\n",
        "        cat3 = torch.cat([x2, up3], dim =1) #256\n",
        "        cat3 = F.relu(nn.BatchNorm2d(num_features=cat3.shape[1])(cat3))\n",
        "        cat3 = self.dropout(cat3)\n",
        "\n",
        "        ## Reduce no_kf channels by half\n",
        "\n",
        "        cat3 = F.relu(self.identity(cat3, n_in = cat3.shape[1], n_out = int(cat3.shape[1]/2))) #128\n",
        "        cat3 = self.dropout(cat3)\n",
        "        cat3 = F.relu(self.identity(cat3, n_in = cat3.shape[1], n_out = int(cat3.shape[1]/2))) # 64\n",
        "\n",
        "        ## Upsampling\n",
        "        up4 = nn.ConvTranspose2d(in_channels = cat3.shape[1], out_channels = cat3.shape[1],kernel_size= 2, stride = 2, padding = 0)(cat3)\n",
        "        cat4 = torch.cat([x1, up4], dim = 1) #128\n",
        "        cat4 = F.relu(nn.BatchNorm2d(num_features=cat4.shape[1])(cat4))\n",
        "        cat4 = self.dropout(cat4)\n",
        "\n",
        "        ##reduce no_channels by half\n",
        "        cat4 = F.relu(self.identity(cat4, n_in = cat4.shape[1], n_out = int(cat4.shape[1]/2)))\n",
        "        cat4 = self.dropout(cat4)\n",
        "        cat4 = F.relu(self.identity(cat4, n_in = cat4.shape[1], n_out = 1))\n",
        "\n",
        "        output = torch.sigmoid(cat4)\n",
        "\n",
        "        return output\n",
        "        \n",
        "\n",
        "model = ResUnet(resblock, 256, 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT9kVcsRfkZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c8911f86-45aa-4fd3-89c1-c36fe8100ae2"
      },
      "source": [
        "import torch\n",
        "## testblock\n",
        "test_tensor = torch.randint(low = 1, high = 256, size = (16, 3, 256, 256)).type(torch.float32)\n",
        "with torch.no_grad():\n",
        "    output = model(test_tensor)\n",
        "\n",
        "print(f\"With input shape of [16, 3, 256, 256]\\nExpected output shape is [16, 1, 256, 256]\\nActual output shape is {output.shape}\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With input shape of [16, 3, 256, 256]\n",
            "Expected output shape is [16, 1, 256, 256]\n",
            "Actual output shape is torch.Size([16, 1, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ZYDocMiHQX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KH6supZiQ-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Evaluation metrics\n",
        "def dice_score(y_pred, y_true, eps = 0.001):\n",
        "    \n",
        "\n",
        "    pred = y_pred.view(y_pred.shape[0], -1).float()\n",
        "    true = y_true.view(y_true.shape[0], -1).float()\n",
        "\n",
        "    numerator = 2 * torch.sum(pred*true, dim = 1) + eps \n",
        "    denominator = torch.sum(pred, dim =1 ) + torch.sum(true, dim =1) + eps\n",
        "    dice_score = numerator /denominator\n",
        "    return dice_score.unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hplAbSDBjg7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## Customized loss function for image segmentation\n",
        "def dice_loss(y_pred, y_true, eps = 0.001):\n",
        "    \n",
        "\n",
        "    pred = y_pred.view(-1)\n",
        "    true = y_true.view(-1)\n",
        "    intersection = (pred * true).sum()\n",
        "    \n",
        "    return 1 - ((2. * intersection + eps) /\n",
        "              (pred.sum() + true.sum() + eps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFfghszisJfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}